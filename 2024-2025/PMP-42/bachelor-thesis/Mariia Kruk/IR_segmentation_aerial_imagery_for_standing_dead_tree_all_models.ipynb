{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "import albumentations as A\n",
        "from scipy.ndimage import binary_dilation\n",
        "from torch.amp import GradScaler, autocast\n",
        "import gc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import logging\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from google.colab import files\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "logging.basicConfig(filename='training_segnet.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "files.upload()\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d meteahishali/aerial-imagery-for-standing-dead-tree-segmentation -p /content\n",
        "!unzip /content/aerial-imagery-for-standing-dead-tree-segmentation.zip -d /content/aerial-imagery-for-standing-dead-tree-segmentation\n"
      ],
      "metadata": {
        "id": "3AfpOdxukKNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n",
        "!pip install opencv-python numpy matplotlib scikit-learn torch torchvision albumentations scipy pydensecrf tqdm segmentation-models-pytorch\n",
        "import pydensecrf.densecrf as dcrf\n",
        "from pydensecrf.utils import unary_from_softmax\n",
        "import segmentation_models_pytorch as smp"
      ],
      "metadata": {
        "id": "Y_wrcXW4qUZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1):\n",
        "        super(SegNet, self).__init__()\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.pool1 = nn.MaxPool2d(2, 2, return_indices=True)\n",
        "\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.pool2 = nn.MaxPool2d(2, 2, return_indices=True)\n",
        "\n",
        "        self.enc3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.pool3 = nn.MaxPool2d(2, 2, return_indices=True)\n",
        "\n",
        "        self.unpool3 = nn.MaxUnpool2d(2, 2)\n",
        "        self.dec3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.unpool2 = nn.MaxUnpool2d(2, 2)\n",
        "        self.dec2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.unpool1 = nn.MaxUnpool2d(2, 2)\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, out_channels, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, idx1 = self.pool1(self.enc1(x))\n",
        "        x, idx2 = self.pool2(self.enc2(x))\n",
        "        x, idx3 = self.pool3(self.enc3(x))\n",
        "        x = self.unpool3(x, idx3)\n",
        "        x = self.dec3(x)\n",
        "        x = self.unpool2(x, idx2)\n",
        "        x = self.dec2(x)\n",
        "        x = self.unpool1(x, idx1)\n",
        "        x = self.dec1(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "mxZ1Rh8vWfIq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HRNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1):\n",
        "        super(HRNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.upconv = nn.ConvTranspose2d(128, out_channels, 4, stride=2, padding=1)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((256, 256))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.upconv(x)\n",
        "        x = self.pool(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kvfSChzgZJNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denormalize_image(image, mean, std):\n",
        "    image = image.copy()\n",
        "    for c in range(image.shape[0]):\n",
        "        image[c] = (image[c] * std[c]) + mean[c]\n",
        "    return np.clip(image, 0, 1)\n",
        "\n",
        "def preprocess_aerial(image, is_nrg=False, image_path=\"unknown\"):\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    if is_nrg:\n",
        "        if image.shape[-1] != 3:\n",
        "            logging.warning(f\"Expected 3 channels at {image_path}, got {image.shape[-1]}\")\n",
        "            return None\n",
        "        nir = cv2.equalizeHist((image[:, :, 0] * 255).astype(np.uint8)).astype(np.float32) / 255.0\n",
        "        image = np.stack([nir, image[:, :, 1], image[:, :, 2]], axis=-1)\n",
        "    image = np.clip(image * 1.2, 0, 1)\n",
        "    if np.any(np.isnan(image)) or np.any(np.isinf(image)):\n",
        "        logging.error(f\"NaN/Inf in {image_path}\")\n",
        "        return None\n",
        "    return image\n",
        "\n",
        "def load_image_and_mask(image_path, mask_path, target_size=(256, 256)):\n",
        "    try:\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
        "        if image is None or image.shape[0] < 128 or image.shape[1] < 128:\n",
        "            return None, None\n",
        "        is_nrg = \"NRG\" in os.path.basename(image_path)\n",
        "        image = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
        "        image = preprocess_aerial(image, is_nrg, image_path)\n",
        "        if image is None:\n",
        "            return None, None\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if mask is None:\n",
        "            return None, None\n",
        "        mask = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "        mask = (mask > 128).astype(np.float32)\n",
        "        mask = binary_dilation(mask, iterations=1).astype(np.float32)\n",
        "        if mask.sum() < 5:\n",
        "            with open(\"empty_masks.log\", \"a\") as f:\n",
        "                f.write(f\"Empty mask for {image_path} (sum={mask.sum()})\\n\")\n",
        "            return None, None\n",
        "        return image, mask\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in {image_path}: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def apply_nrg_normalization(image, mean, std):\n",
        "    image = image.transpose(2, 0, 1)\n",
        "    image = torch.from_numpy(image).float()\n",
        "    mean = torch.tensor(mean, dtype=torch.float32).view(-1, 1, 1)\n",
        "    std = torch.tensor(std, dtype=torch.float32).view(-1, 1, 1)\n",
        "    image = (image - mean) / (std + 1e-7)\n",
        "    image = torch.clamp(image, -5, 5)\n",
        "    if torch.any(torch.isnan(image)) or torch.any(torch.isinf(image)):\n",
        "        logging.error(\"NaN/Inf in normalized image\")\n",
        "        return None\n",
        "    return image\n",
        "\n",
        "def preprocess_and_save(image_paths, mask_paths, mean, std, save_dir):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    valid_indices = []\n",
        "    for i, (img_path, mask_path) in enumerate(tqdm(zip(image_paths, mask_paths), total=len(image_paths))):\n",
        "        image, mask = load_image_and_mask(img_path, mask_path)\n",
        "        if image is None or mask is None:\n",
        "            continue\n",
        "        image = apply_nrg_normalization(image, mean, std)\n",
        "        if image is None:\n",
        "            continue\n",
        "        mask = torch.from_numpy(mask).float().unsqueeze(0)\n",
        "        np.save(os.path.join(save_dir, f\"image_{i}.npy\"), image.numpy(), allow_pickle=False)\n",
        "        np.save(os.path.join(save_dir, f\"mask_{i}.npy\"), mask.numpy(), allow_pickle=False)\n",
        "        valid_indices.append(i)\n",
        "    return valid_indices"
      ],
      "metadata": {
        "id": "rTCAe_QbWQro"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AerialDataset(Dataset):\n",
        "    def __init__(self, preprocessed_dir, mean, std, augmenter=None):\n",
        "        self.image_files = sorted([f for f in os.listdir(preprocessed_dir) if f.startswith(\"image_\")])\n",
        "        self.mask_files = sorted([f for f in os.listdir(preprocessed_dir) if f.startswith(\"mask_\")])\n",
        "        self.preprocessed_dir = preprocessed_dir\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.augmenter = augmenter\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.load(os.path.join(self.preprocessed_dir, self.image_files[idx]), mmap_mode='r')\n",
        "        mask = np.load(os.path.join(self.preprocessed_dir, self.mask_files[idx]), mmap_mode='r')\n",
        "        image = torch.from_numpy(image.copy()).float()\n",
        "        mask = torch.from_numpy(mask.copy()).float()\n",
        "        if self.augmenter:\n",
        "            img_3ch = denormalize_image(image.numpy(), self.mean, self.std).transpose(1, 2, 0)\n",
        "            augmented = self.augmenter(image=img_3ch, mask=mask.squeeze().numpy())\n",
        "            aug_img, aug_mask = augmented['image'], augmented['mask']\n",
        "            if aug_mask.sum() >= 5:\n",
        "                image = apply_nrg_normalization(aug_img, self.mean, self.std)\n",
        "                mask = torch.from_numpy(aug_mask).float().unsqueeze(0)\n",
        "        return image, mask\n"
      ],
      "metadata": {
        "id": "LUuoUtjXWShC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"aerial-imagery-for-standing-dead-tree-segmentation/USA_segmentation\"\n",
        "nrg_image_dir = os.path.join(data_dir, \"NRG_images\")\n",
        "mask_dir = os.path.join(data_dir, \"masks\")\n",
        "\n",
        "for directory in [nrg_image_dir, mask_dir]:\n",
        "    if not os.path.exists(directory):\n",
        "        raise FileNotFoundError(f\"Directory {directory} not found\")\n",
        "\n",
        "nrg_image_files = sorted([f for f in os.listdir(nrg_image_dir) if f.endswith('.png')])\n",
        "mask_files = sorted([f for f in os.listdir(mask_dir) if f.startswith('mask_') and f.endswith('.png')])\n",
        "\n",
        "image_paths = []\n",
        "mask_paths = []\n",
        "for img_file in nrg_image_files:\n",
        "    img_path = os.path.join(nrg_image_dir, img_file)\n",
        "    base_name = img_file.replace(\"NRG_\", \"\")\n",
        "    mask_file = f\"mask_{base_name}\"\n",
        "    mask_path = os.path.join(mask_dir, mask_file)\n",
        "    if os.path.exists(mask_path):\n",
        "        image_paths.append(img_path)\n",
        "        mask_paths.append(mask_path)\n",
        "\n",
        "image_paths = image_paths[:200]\n",
        "mask_paths = mask_paths[:200]\n",
        "\n",
        "mean_nrg = np.array([0.5827, 0.4934, 0.6260])\n",
        "std_nrg = np.array([0.3245, 0.2736, 0.2906])\n",
        "logging.info(f\"NRG mean: {mean_nrg}, std: {std_nrg}\")\n",
        "print(f\"NRG mean: {mean_nrg}, std: {std_nrg}\")\n",
        "\n",
        "\n",
        "valid_indices = preprocess_and_save(image_paths, mask_paths, mean_nrg, std_nrg, \"preprocessed_data_segnet\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zp4VOjaWUfr",
        "outputId": "cc8fe15c-30c6-4804-f26e-dd8c89b941ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NRG mean: [0.5827 0.4934 0.626 ], std: [0.3245 0.2736 0.2906]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:05<00:00, 33.58it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_augmenter():\n",
        "    return A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.Resize(height=256, width=256, p=1.0)\n",
        "    ], additional_targets={'mask': 'mask'})\n",
        "\n",
        "train_idx, val_idx = train_test_split(range(len(valid_indices)), test_size=0.25, random_state=42)\n",
        "train_dataset = AerialDataset(\"preprocessed_data_segnet\", mean_nrg, std_nrg, get_augmenter())\n",
        "val_dataset = AerialDataset(\"preprocessed_data_segnet\", mean_nrg, std_nrg, None)\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    batch = [b for b in batch if b[0] is not None]\n",
        "    if len(batch) <= 1:\n",
        "        return torch.tensor([]), torch.tensor([])\n",
        "    images, masks = zip(*batch)\n",
        "    return torch.stack(images), torch.stack(masks)\n",
        "\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, collate_fn=custom_collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, collate_fn=custom_collate_fn)\n"
      ],
      "metadata": {
        "id": "LPGgLjayWX5J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1e-7):\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    intersection = (y_true_f * y_pred_f).sum()\n",
        "    return (2. * intersection + smooth) / (y_true_f.sum() + y_pred_f.sum() + smooth)\n",
        "\n",
        "def jaccard_index(y_true, y_pred, smooth=1e-7):\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    intersection = (y_true_f * y_pred_f).sum()\n",
        "    union = y_true_f.sum() + y_pred_f.sum() - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "def pixel_accuracy(y_true, y_pred):\n",
        "    y_true_bin = (y_true > 0.5).float()\n",
        "    y_pred_bin = (y_pred > 0.5).float()\n",
        "    return (y_true_bin == y_pred_bin).float().mean()\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, bce_weight=0.3, focal_weight=0.7, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.bce_weight = bce_weight\n",
        "        self.focal_weight = focal_weight\n",
        "        self.gamma = gamma\n",
        "        self.bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(10.0).to(device))\n",
        "\n",
        "    def focal_loss(self, y_pred, y_true):\n",
        "        y_pred = torch.sigmoid(y_pred)\n",
        "        pt = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        focal_weight = (1 - pt).pow(self.gamma)\n",
        "        bce = F.binary_cross_entropy_with_logits(y_pred, y_true, reduction='none')\n",
        "        return (focal_weight * bce).mean()\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        bce = self.bce(y_pred, y_true)\n",
        "        focal = self.focal_loss(y_pred, y_true)\n",
        "        loss = self.bce_weight * bce + self.focal_weight * focal\n",
        "        if y_true.sum() == 0:\n",
        "            return 0.1 * loss\n",
        "        return loss"
      ],
      "metadata": {
        "id": "TrUI0jijWbBn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"SegNet\"\n",
        "model_configs = {\n",
        "    \"DeepLabV3Plus\": {\n",
        "        \"class\": smp.DeepLabV3Plus,\n",
        "        \"save_prefix\": \"deeplabv3plus_hit_uav\",\n",
        "        \"params\": {\"encoder_name\": \"resnet50\", \"in_channels\": 3, \"classes\": 1}\n",
        "    },\n",
        "    \"Unet\": {\n",
        "        \"class\": smp.Unet,\n",
        "        \"save_prefix\": \"unet_hit_uav\",\n",
        "        \"params\": {\"encoder_name\": \"resnet50\", \"in_channels\": 3, \"classes\": 1}\n",
        "    },\n",
        "    \"PSPNet\": {\n",
        "        \"class\": smp.PSPNet,\n",
        "        \"save_prefix\": \"pspnet_hit_uav\",\n",
        "        \"params\": {\"encoder_name\": \"resnet50\", \"in_channels\": 3, \"classes\": 1}\n",
        "    },\n",
        "    \"SegNet\": {\n",
        "        \"class\": SegNet,\n",
        "        \"save_prefix\": \"segnet_hit_uav\",\n",
        "        \"params\": {\"in_channels\": 3, \"out_channels\": 1}\n",
        "    },\n",
        "    \"HRNet\": {\n",
        "        \"class\": HRNet,\n",
        "        \"save_prefix\": \"hrnet_hit_uav\",\n",
        "        \"params\": {\"in_channels\": 3, \"out_channels\": 1}\n",
        "    }\n",
        "}\n",
        "\n",
        "if model_name not in model_configs:\n",
        "    raise ValueError(f\"Model {model_name} is not supported. Choose from {list(model_configs.keys())}\")"
      ],
      "metadata": {
        "id": "12AiU3WpWz2k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_segmentation_model(model_name):\n",
        "    model_class = model_configs[model_name][\"class\"]\n",
        "    model_params = model_configs[model_name][\"params\"]\n",
        "    if model_name in [\"DeepLabV3Plus\", \"Unet\", \"PSPNet\"]:\n",
        "        return model_class(**model_params, encoder_weights=\"imagenet\", activation=None).to(device)\n",
        "    elif model_name in [\"SegNet\", \"HRNet\"]:\n",
        "        return model_class(**model_params).to(device)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model type: {model_name}\")\n",
        "\n",
        "model = get_segmentation_model(model_name)\n",
        "\n",
        "loss_fn = CombinedLoss(bce_weight=0.3, focal_weight=0.7)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
        "scaler = GradScaler('cuda')\n",
        "accumulation_steps = 4\n",
        "warmup_epochs = 2\n",
        "num_epochs = 200\n",
        "warmup_epochs = 5\n",
        "base_lr = 3e-4\n",
        "warmup_lr = 3e-5\n",
        "best_val_iou = 0.0\n",
        "patience = 15\n",
        "history = {'train_loss': [], 'val_loss': [], 'train_iou': [], 'val_iou': []}\n",
        "epochs_no_improve = 0\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    train_loss, train_iou, train_count = 0.0, 0.0, 0\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    data_time = 0.0\n",
        "    forward_time = 0.0\n",
        "    for i, (images, masks) in enumerate(train_loader):\n",
        "        data_start = time.time()\n",
        "        if images.numel() == 0 or images.size(0) <= 1:\n",
        "            continue\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        data_time += time.time() - data_start\n",
        "\n",
        "        forward_start = time.time()\n",
        "        with autocast('cuda'):\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, masks) / accumulation_steps\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            continue\n",
        "        scaler.scale(loss).backward()\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "        forward_time += time.time() - forward_start\n",
        "\n",
        "        train_loss += loss.item() * accumulation_steps * images.size(0)\n",
        "        preds = torch.sigmoid(outputs).detach()\n",
        "        train_iou += jaccard_index(masks, preds).item() * images.size(0)\n",
        "        train_count += images.size(0)\n",
        "        del images, masks, outputs, preds\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    if train_count > 0:\n",
        "        train_loss /= train_count\n",
        "        train_iou /= train_count\n",
        "\n",
        "    if epoch < warmup_epochs:\n",
        "        lr = 1e-3 * (epoch + 1) / warmup_epochs\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "    else:\n",
        "        scheduler.step()\n",
        "\n",
        "    val_loss, val_iou = train_loss, train_iou\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.eval()\n",
        "        val_loss, val_iou, val_count = 0.0, 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, masks in val_loader:\n",
        "                if images.numel() == 0 or images.size(0) <= 1:\n",
        "                    continue\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "                with autocast('cuda'):\n",
        "                    outputs = model(images)\n",
        "                    loss = loss_fn(outputs, masks)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                preds = torch.sigmoid(outputs).detach()\n",
        "                val_iou += jaccard_index(masks, preds).item() * images.size(0)\n",
        "                val_count += images.size(0)\n",
        "                del images, masks, outputs, preds\n",
        "                torch.cuda.empty_cache()\n",
        "        if val_count > 0:\n",
        "            val_loss /= val_count\n",
        "            val_iou /= val_count\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['train_iou'].append(train_iou)\n",
        "    history['val_iou'].append(val_iou)\n",
        "\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    logging.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "                 f\"Train IoU: {train_iou:.4f}, Val IoU: {val_iou:.4f}, LR: {current_lr:.6f}, \"\n",
        "                 f\"Data: {data_time:.2f}s, Forward: {forward_time:.2f}s, Time: {time.time() - start_time:.2f}s\")\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "          f\"Train IoU: {train_iou:.4f}, Val IoU: {val_iou:.4f}, LR: {current_lr:.6f}, \"\n",
        "          f\"Data: {data_time:.2f}s, Forward: {forward_time:.2f}s, Time: {time.time() - start_time:.2f}s\")\n",
        "\n",
        "    if val_iou > best_val_iou:\n",
        "        best_val_iou = val_iou\n",
        "        model_path = f\"best_{model_configs[model_name]['save_prefix']}.pth\"\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        logging.info(f\"New best model saved at epoch {epoch+1} with Val IoU: {val_iou:.4f}\")\n",
        "        print(f\"New best model saved at epoch {epoch+1} with Val IoU: {val_iou:.4f}\")\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        model_path = f\"last_{model_configs[model_name]['save_prefix']}.pth\"\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "YoVnVX88_4TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, val_loader, mean_nrg, std_nrg, use_crf=False):\n",
        "    start_time = time.time()\n",
        "    model.eval()\n",
        "    model_path = f\"best_{model_configs[model_name]['save_prefix']}.pth\"\n",
        "    if os.path.exists(model_path):\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        logging.info(f\"Loaded {model_path}\")\n",
        "        print(f\"Loaded {model_path}\")\n",
        "    else:\n",
        "        logging.warning(\"No saved model\")\n",
        "        print(\"No saved model\")\n",
        "\n",
        "    y_pred, y_true, per_image_iou = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            if images.numel() == 0 or images.size(0) <= 1:\n",
        "                continue\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            with autocast('cuda'):\n",
        "                outputs = model(images)\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "            images_np = images.cpu().numpy()\n",
        "\n",
        "            refined_preds = probs > 0.5 if not use_crf else np.stack([\n",
        "                apply_crf_wrapper((denormalize_image(images_np[i], mean_nrg, std_nrg).transpose(1, 2, 0), probs[i].squeeze()))\n",
        "                for i in range(probs.shape[0])\n",
        "            ])\n",
        "\n",
        "            best_preds = refined_preds > 0.5\n",
        "            best_preds = torch.from_numpy(best_preds).to(device)\n",
        "\n",
        "            y_pred.append(best_preds.cpu().numpy())\n",
        "            y_true.append(masks.cpu().numpy())\n",
        "            for i in range(images.size(0)):\n",
        "                iou = jaccard_index(masks[i:i+1], best_preds[i:i+1])\n",
        "                per_image_iou.append(iou.item())\n",
        "\n",
        "            del images, masks, outputs, probs, images_np, refined_preds, best_preds\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    y_pred = np.concatenate(y_pred, axis=0)\n",
        "    y_true = np.concatenate(y_true, axis=0)\n",
        "\n",
        "    val_iou = jaccard_index(torch.tensor(y_true), torch.tensor(y_pred))\n",
        "    val_dice = dice_coefficient(torch.tensor(y_true), torch.tensor(y_pred))\n",
        "    val_accuracy = pixel_accuracy(torch.tensor(y_true), torch.tensor(y_pred))\n",
        "\n",
        "    logging.info(f\"Validation: IoU: {val_iou:.4f}, Dice: {val_dice:.4f}, Accuracy: {val_accuracy:.4f}, \"\n",
        "                 f\"IoU (mean ± std): {np.mean(per_image_iou):.4f} ± {np.std(per_image_iou):.4f}, Time: {time.time() - start_time:.2f}s\")\n",
        "    print(f\"Validation: IoU: {val_iou:.4f}, Dice: {val_dice:.4f}, Accuracy: {val_accuracy:.4f}, \"\n",
        "          f\"IoU (mean ± std): {np.mean(per_image_iou):.4f} ± {np.std(per_image_iou):.4f}, Time: {time.time() - start_time:.2f}s\")\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true.flatten(), y_pred.flatten(), labels=[0, 1]).ravel()\n",
        "    logging.info(f\"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")\n",
        "    print(f\"Confusion Matrix: TN={tn}, FP={fp}, FN={fn}, TP={tp}\")\n",
        "\n",
        "    return y_pred, y_true, per_image_iou\n",
        "\n",
        "y_pred, y_true, per_image_iou = evaluate_model(model, val_loader, mean_nrg, std_nrg, use_crf=False)\n"
      ],
      "metadata": {
        "id": "HNtv3f17XbSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "for i, (images, masks) in enumerate(val_loader):\n",
        "    if images.numel() == 0 or images.size(0) <= 1:\n",
        "        continue\n",
        "    images = images[:3].to(device)\n",
        "    with torch.no_grad():\n",
        "        with autocast('cuda'):\n",
        "            outputs = model(images)\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "            images_np = images.cpu().numpy()\n",
        "\n",
        "    images = images.cpu().numpy()\n",
        "    masks = masks[:3].cpu().numpy()\n",
        "    for j in range(min(3, len(images))):\n",
        "        plt.subplot(3, 3, j*3 + 1)\n",
        "        plt.imshow(denormalize_image(images[j], mean_nrg, std_nrg).transpose(1, 2, 0))\n",
        "        plt.title('NRG Image')\n",
        "        plt.axis('off')\n",
        "        plt.subplot(3, 3, j*3 + 2)\n",
        "        plt.imshow(masks[j].squeeze(), cmap='gray')\n",
        "        plt.title('True Mask')\n",
        "        plt.axis('off')\n",
        "        plt.subplot(3, 3, j*3 + 3)\n",
        "        plt.imshow(probs[j].squeeze() > 0.5, cmap='gray')\n",
        "        plt.title('Predicted Mask')\n",
        "        plt.axis('off')\n",
        "    break\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['train_loss'], label='Train Loss')\n",
        "plt.plot(history['val_loss'], label='Val Loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['train_iou'], label='Train IoU')\n",
        "plt.plot(history['val_iou'], label='Val IoU')\n",
        "plt.title('Jaccard Index')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "np.save(f'y_pred_{model_configs[model_name][\"save_prefix\"]}.npy', y_pred)\n",
        "np.save(f'y_true_{model_configs[model_name][\"save_prefix\"]}.npy', y_true)\n",
        "np.save(f'per_image_iou_{model_configs[model_name][\"save_prefix\"]}.npy', per_image_iou)"
      ],
      "metadata": {
        "id": "D3nMjUkLz838"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}