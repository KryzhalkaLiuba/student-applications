{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89k4GFFOGGzj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "import albumentations as A\n",
        "from torch.amp import GradScaler, autocast\n",
        "import gc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import torch.nn.functional as F\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if not torch.cuda.is_available():\n",
        "    logging.warning(\"CUDA is not available. Running on CPU, which will be slow.\")\n",
        "    print(\"CUDA is not available. Running on CPU, which will be slow.\")\n",
        "\n",
        "files.upload()\n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d pandrii000/hituav-a-highaltitude-infrared-thermal-dataset -p /content\n",
        "!unzip /content/hituav-a-highaltitude-infrared-thermal-dataset.zip -d /content/hituav-a-highaltitude-infrared-thermal-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPOTNXRIKDFV"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/lucasb-eyer/pydensecrf.git\n",
        "!pip install opencv-python numpy matplotlib scikit-learn torch torchvision albumentations scipy pydensecrf tqdm segmentation-models-pytorch\n",
        "import segmentation_models_pytorch as smp\n",
        "import pydensecrf.densecrf as dcrf\n",
        "from pydensecrf.utils import unary_from_softmax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SegNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=5):\n",
        "        super(SegNet, self).__init__()\n",
        "        # Енкодер\n",
        "        self.enc1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.pool1 = nn.MaxPool2d(2, 2, return_indices=True)\n",
        "\n",
        "        self.enc2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.pool2 = nn.MaxPool2d(2, 2, return_indices=True)\n",
        "\n",
        "        self.enc3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.pool3 = nn.MaxPool2d(2, 2, return_indices=True)\n",
        "\n",
        "        # Декодер\n",
        "        self.unpool3 = nn.MaxUnpool2d(2, 2)\n",
        "        self.dec3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.unpool2 = nn.MaxUnpool2d(2, 2)\n",
        "        self.dec2 = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.unpool1 = nn.MaxUnpool2d(2, 2)\n",
        "        self.dec1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, num_classes, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, idx1 = self.pool1(self.enc1(x))\n",
        "        x, idx2 = self.pool2(self.enc2(x))\n",
        "        x, idx3 = self.pool3(self.enc3(x))\n",
        "        x = self.unpool3(x, idx3)\n",
        "        x = self.dec3(x)\n",
        "        x = self.unpool2(x, idx2)\n",
        "        x = self.dec2(x)\n",
        "        x = self.unpool1(x, idx1)\n",
        "        x = self.dec1(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Lo_tZakCuKrr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class HRNet(nn.Module):\n",
        "    def __init__(self, in_channels=1,num_classes=5):\n",
        "        super(HRNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.out = nn.Conv2d(64, num_classes, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "t1EQURXmuNVI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def denormalize_image(image, mean, std):\n",
        "    image = image.copy()\n",
        "    image = (image * std) + mean\n",
        "    return np.clip(image, 0, 1)\n",
        "\n",
        "def preprocess_infrared(image, image_path=\"unknown\"):\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    if image.ndim == 2:\n",
        "        image = image[..., np.newaxis]\n",
        "    if image.shape[-1] != 1:\n",
        "        logging.warning(f\"Expected 1 channel at {image_path}, got {image.shape[-1]}\")\n",
        "        return None\n",
        "\n",
        "    image_eq = cv2.equalizeHist((image.squeeze() * 255).astype(np.uint8))\n",
        "    image_eq = image_eq.astype(np.float32) / 255.0\n",
        "    image = np.clip(image_eq * 1.5, 0, 1)\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    image_clahe = clahe.apply((image.squeeze() * 255).astype(np.uint8))\n",
        "    image = np.clip(image_clahe.astype(np.float32) / 255.0 * 1.2, 0, 1)\n",
        "\n",
        "    if np.any(np.isnan(image)) or np.any(np.isinf(image)):\n",
        "        logging.error(f\"NaN/Inf in {image_path}\")\n",
        "        return None\n",
        "    return image[..., np.newaxis]\n",
        "\n",
        "def apply_infrared_normalization(image, mean, std):\n",
        "    image = image.transpose(2, 0, 1)\n",
        "    image = torch.from_numpy(image).float()\n",
        "    mean = torch.tensor(mean, dtype=torch.float32).view(-1, 1, 1)\n",
        "    std = torch.tensor(std, dtype=torch.float32).view(-1, 1, 1)\n",
        "    image = (image - mean) / (std + 1e-7)\n",
        "    image = torch.clamp(image, -5, 5)\n",
        "    if torch.any(torch.isnan(image)) or torch.any(torch.isinf(image)):\n",
        "        logging.error(\"NaN/Inf in normalized image\")\n",
        "        return None\n",
        "    return image\n",
        "\n",
        "def load_image_and_mask(image_path, label_path, classes, target_size=(256, 256)):\n",
        "    try:\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if image is None or image.shape[0] < 128 or image.shape[1] < 128:\n",
        "            return None, None\n",
        "        image = cv2.resize(image, target_size, interpolation=cv2.INTER_LINEAR)\n",
        "        image = preprocess_infrared(image, image_path)\n",
        "        if image is None:\n",
        "            return None, None\n",
        "\n",
        "        with open(label_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        mask = np.zeros(target_size, dtype=np.int64)\n",
        "        img_height, img_width = target_size\n",
        "        for line in lines:\n",
        "            data = list(map(float, line.strip().split()))\n",
        "            class_id = int(data[0])\n",
        "            if class_id >= len(classes):\n",
        "                logging.warning(f\"Invalid class_id {class_id} in {label_path}\")\n",
        "                continue\n",
        "            x_center, y_center, width, height = data[1:5]\n",
        "            x_min = int((x_center - width / 2) * img_width)\n",
        "            x_max = int((x_center + width / 2) * img_width)\n",
        "            y_min = int((y_center - height / 2) * img_height)\n",
        "            y_max = int((y_center + height / 2) * img_height)\n",
        "            x_min, x_max = max(0, x_min), min(img_width, x_max)\n",
        "            y_min, y_max = max(0, y_min), min(img_height, y_max)\n",
        "            mask[y_min:y_max, x_min:x_max] = class_id + 1\n",
        "\n",
        "        if mask.sum() < 5:\n",
        "            with open(\"empty_masks.log\", \"a\") as f:\n",
        "                f.write(f\"Empty mask for {image_path} (sum={mask.sum()})\\n\")\n",
        "            return None, None\n",
        "        return image, mask\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in {image_path}: {str(e)}\")\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "FPGME2_AucL5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_and_save(image_paths, label_paths, mean, std, save_dir, classes):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    valid_indices = []\n",
        "    images_to_display = []\n",
        "    masks_to_display = []\n",
        "    display_limit = 3\n",
        "\n",
        "    for i, (img_path, lbl_path) in enumerate(tqdm(zip(image_paths, label_paths), total=len(image_paths))):\n",
        "        image, mask = load_image_and_mask(img_path, lbl_path, classes)\n",
        "        if image is None or mask is None:\n",
        "            continue\n",
        "\n",
        "        if len(images_to_display) < display_limit:\n",
        "            images_to_display.append(image.squeeze())\n",
        "            masks_to_display.append(mask)\n",
        "\n",
        "        image = apply_infrared_normalization(image, mean, std)\n",
        "        if image is None:\n",
        "            continue\n",
        "        mask = torch.from_numpy(mask).long()\n",
        "        np.save(os.path.join(save_dir, f\"image_{i}.npy\"), image.numpy(), allow_pickle=False)\n",
        "        np.save(os.path.join(save_dir, f\"mask_{i}.npy\"), mask.numpy(), allow_pickle=False)\n",
        "        valid_indices.append(i)\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    classes_with_bg = ['Background', 'Person', 'Bicycle', 'Car', 'OtherVehicle']\n",
        "    colors = ['#000000', '#FF0000', '#00FF00', '#0000FF', '#FFFF00']\n",
        "    cmap = plt.cm.colors.ListedColormap(colors)\n",
        "    bounds = range(6)\n",
        "    norm = plt.cm.colors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "    for j in range(len(images_to_display)):\n",
        "        plt.subplot(2, 3, j + 1)\n",
        "        plt.imshow(images_to_display[j], cmap='gray')\n",
        "        plt.title('Raw Infrared Image')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(2, 3, j + 4)\n",
        "        mask_display = masks_to_display[j]\n",
        "        im = plt.imshow(mask_display, cmap=cmap, norm=norm, alpha=0.8)\n",
        "        plt.title('Ground Truth Mask')\n",
        "        plt.axis('off')\n",
        "        cbar = plt.colorbar(im, ticks=range(5), shrink=0.5)\n",
        "        cbar.ax.set_yticklabels(classes_with_bg)\n",
        "        cbar.set_label('Classes')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return valid_indices\n"
      ],
      "metadata": {
        "id": "y2Q2AmJcuiyb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HITUAVDataset(Dataset):\n",
        "    def __init__(self, preprocessed_dir, mean, std, augmenter=None):\n",
        "        self.image_files = sorted([f for f in os.listdir(preprocessed_dir) if f.startswith(\"image_\")])\n",
        "        self.mask_files = sorted([f for f in os.listdir(preprocessed_dir) if f.startswith(\"mask_\")])\n",
        "        self.preprocessed_dir = preprocessed_dir\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.augmenter = augmenter\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.load(os.path.join(self.preprocessed_dir, self.image_files[idx]), mmap_mode='r')\n",
        "        mask = np.load(os.path.join(self.preprocessed_dir, self.mask_files[idx]), mmap_mode='r')\n",
        "        image = torch.from_numpy(image.copy()).float()\n",
        "        mask = torch.from_numpy(mask.copy()).long()\n",
        "        if self.augmenter:\n",
        "            img_1ch = denormalize_image(image.numpy(), self.mean, self.std)[0]\n",
        "            mask_np = mask.numpy()\n",
        "            augmented = self.augmenter(image=img_1ch, mask=mask_np)\n",
        "            aug_img, aug_mask = augmented['image'], augmented['mask']\n",
        "            if aug_mask.sum() >= 5:\n",
        "                aug_img = aug_img[..., np.newaxis]\n",
        "                image = apply_infrared_normalization(aug_img, self.mean, self.std)\n",
        "                mask = torch.from_numpy(aug_mask).long()\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "ljYzbElEulXR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/hituav-a-highaltitude-infrared-thermal-dataset/hit-uav\"\n",
        "image_dir = os.path.join(data_dir, \"images\")\n",
        "label_dir = os.path.join(data_dir, \"labels\")\n",
        "\n",
        "for directory in [image_dir, label_dir]:\n",
        "    if not os.path.exists(directory):\n",
        "        raise FileNotFoundError(f\"Directory {directory} not found\")\n",
        "\n",
        "splits = ['train', 'val']\n",
        "image_paths = []\n",
        "label_paths = []\n",
        "for split in splits:\n",
        "    split_image_dir = os.path.join(image_dir, split)\n",
        "    split_label_dir = os.path.join(label_dir, split)\n",
        "    label_files = sorted([f for f in os.listdir(split_label_dir) if f.endswith('.txt')])\n",
        "    for lbl_file in label_files:\n",
        "        img_file = lbl_file.replace('.txt', '.jpg')\n",
        "        img_path = os.path.join(split_image_dir, img_file)\n",
        "        lbl_path = os.path.join(split_label_dir, lbl_file)\n",
        "        if os.path.exists(img_path):\n",
        "            image_paths.append(img_path)\n",
        "            label_paths.append(lbl_path)\n",
        "\n",
        "image_paths = image_paths[:200]\n",
        "label_paths = label_paths[:200]\n",
        "\n",
        "mean_ir = np.array([0.5])\n",
        "std_ir = np.array([0.2])\n",
        "logging.info(f\"Infrared mean: {mean_ir}, std: {std_ir}\")\n",
        "print(f\"Infrared mean: {mean_ir}, std: {std_ir}\")\n",
        "\n",
        "classes = ['Person', 'Bicycle', 'Car', 'OtherVehicle']\n",
        "\n",
        "valid_indices = preprocess_and_save(image_paths, label_paths, mean_ir, std_ir, \"preprocessed_data_hit_uav\", classes)"
      ],
      "metadata": {
        "id": "EhpSDM3nurng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_augmenter():\n",
        "    return A.Compose([\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.Resize(height=256, width=256, p=1.0)\n",
        "    ], additional_targets={'mask': 'mask'})\n",
        "\n",
        "train_idx, val_idx = train_test_split(range(len(valid_indices)), test_size=0.25, random_state=42)\n",
        "train_dataset = HITUAVDataset(\"preprocessed_data_hit_uav\", mean_ir, std_ir, get_augmenter())\n",
        "val_dataset = HITUAVDataset(\"preprocessed_data_hit_uav\", mean_ir, std_ir, None)\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    batch = [b for b in batch if b[0] is not None]\n",
        "    if len(batch) <= 1:\n",
        "        return torch.tensor([]), torch.tensor([])\n",
        "    images, masks = zip(*batch)\n",
        "    return torch.stack(images), torch.stack(masks)\n",
        "\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, collate_fn=custom_collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, collate_fn=custom_collate_fn)\n"
      ],
      "metadata": {
        "id": "mmLBrxMzuw9Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coefficient(y_true, y_pred, num_classes, smooth=1e-7):\n",
        "    dice_scores = []\n",
        "    for cls in range(num_classes):\n",
        "        y_true_cls = (y_true == cls).float()\n",
        "        y_pred_cls = (y_pred == cls).float()\n",
        "        intersection = (y_true_cls * y_pred_cls).sum()\n",
        "        score = (2. * intersection + smooth) / (y_true_cls.sum() + y_pred_cls.sum() + smooth)\n",
        "        dice_scores.append(score.item())\n",
        "    return np.mean(dice_scores)\n",
        "\n",
        "def jaccard_index(y_true, y_pred, num_classes, smooth=1e-7):\n",
        "    iou_scores = []\n",
        "    for cls in range(num_classes):\n",
        "        y_true_cls = (y_true == cls).float()\n",
        "        y_pred_cls = (y_pred == cls).float()\n",
        "        intersection = (y_true_cls * y_pred_cls).sum()\n",
        "        union = y_true_cls.sum() + y_pred_cls.sum() - intersection\n",
        "        score = (intersection + smooth) / (union + smooth)\n",
        "        iou_scores.append(score.item())\n",
        "    return np.mean(iou_scores)\n",
        "\n",
        "def pixel_accuracy(y_true, y_pred):\n",
        "    return (y_true == y_pred).float().mean()"
      ],
      "metadata": {
        "id": "K6DdJWGS-Lub"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"PSPNet\"\n",
        "model_configs = {\n",
        "    \"DeepLabV3Plus\": {\n",
        "        \"class\": smp.DeepLabV3Plus,\n",
        "        \"save_prefix\": \"deeplabv3plus_hit_uav\",\n",
        "        \"params\": {\"encoder_name\": \"resnet50\", \"in_channels\": 1, \"classes\": 5}\n",
        "    },\n",
        "    \"Unet\": {\n",
        "        \"class\": smp.Unet,\n",
        "        \"save_prefix\": \"unet_hit_uav\",\n",
        "        \"params\": {\"encoder_name\": \"resnet50\", \"in_channels\": 1, \"classes\": 5}\n",
        "    },\n",
        "    \"PSPNet\": {\n",
        "        \"class\": smp.PSPNet,\n",
        "        \"save_prefix\": \"pspnet_hit_uav\",\n",
        "        \"params\": {\"encoder_name\": \"resnet50\", \"in_channels\": 1, \"classes\": 5}\n",
        "    },\n",
        "    \"SegNet\": {\n",
        "        \"class\": SegNet,\n",
        "        \"save_prefix\": \"segnet_hit_uav\",\n",
        "        \"params\": {\"in_channels\": 1, \"out_channels\": 5}\n",
        "    },\n",
        "    \"HRNet\": {\n",
        "        \"class\": HRNet,\n",
        "        \"save_prefix\": \"hrnet_hit_uav\",\n",
        "        \"params\": {\"in_channels\": 1, \"out_channels\": 5}\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "NoKb-TNlCyxV"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model_name not in model_configs:\n",
        "    raise ValueError(f\"Model {model_name} is not supported. Choose from {list(model_configs.keys())}\")\n",
        "\n",
        "\n",
        "def get_segmentation_model(model_name):\n",
        "\n",
        "    if model_name not in model_configs:\n",
        "        raise ValueError(f\"Model {model_name} not found in model_configs\")\n",
        "\n",
        "    model_class = model_configs[model_name][\"class\"]\n",
        "    model_params = model_configs[model_name][\"params\"].copy()\n",
        "\n",
        "    if model_name in [\"DeepLabV3Plus\", \"Unet\", \"PSPNet\"]:\n",
        "        model_params[\"encoder_weights\"] = \"imagenet\"\n",
        "        model_params[\"activation\"] = None\n",
        "        return model_class(**model_params)\n",
        "\n",
        "    elif model_name in [\"SegNet\", \"HRNet\"]:\n",
        "        return model_class(in_channels=model_params[\"in_channels\"], num_classes=model_params[\"out_channels\"])\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model type: {model_name}\")\n",
        "\n",
        "num_classes = 5\n",
        "model = get_segmentation_model(model_name).to(device)"
      ],
      "metadata": {
        "id": "GVEZs_D1Cr9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = torch.tensor([0.1, 2.0, 2.0, 2.0, 2.0], device=device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)\n",
        "scaler = GradScaler('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "accumulation_steps = 4\n",
        "warmup_epochs = 2\n",
        "num_epochs = 500\n",
        "best_val_iou = 0.0\n",
        "patience = 3\n",
        "history = {'train_loss': [], 'val_loss': [], 'train_iou': [], 'val_iou': []}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    train_loss, train_iou, train_count = 0.0, 0.0, 0\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    data_time = 0.0\n",
        "    forward_time = 0.0\n",
        "    for i, (images, masks) in enumerate(train_loader):\n",
        "        data_start = time.time()\n",
        "        if images.numel() == 0 or images.size(0) <= 1:\n",
        "            continue\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "        data_time += time.time() - data_start\n",
        "\n",
        "        forward_start = time.time()\n",
        "        with autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, masks) / accumulation_steps\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            continue\n",
        "        scaler.scale(loss).backward()\n",
        "        if (i + 1) % accumulation_steps == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "        forward_time += time.time() - forward_start\n",
        "\n",
        "        train_loss += loss.item() * accumulation_steps * images.size(0)\n",
        "        preds = torch.argmax(outputs, dim=1).detach()\n",
        "        train_iou += jaccard_index(masks, preds, num_classes=5).item() * images.size(0)\n",
        "        del images, masks, outputs, preds\n",
        "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    if train_count > 0:\n",
        "        train_loss /= train_count\n",
        "        train_iou /= train_count\n",
        "\n",
        "    if epoch < warmup_epochs:\n",
        "        lr = 1e-3 * (epoch + 1) / warmup_epochs\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "    else:\n",
        "        scheduler.step()\n",
        "\n",
        "    val_loss, val_iou = train_loss, train_iou\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.eval()\n",
        "        val_loss, val_iou, val_count = 0.0, 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, masks in val_loader:\n",
        "                if images.numel() == 0 or images.size(0) <= 1:\n",
        "                    continue\n",
        "                images, masks = images.to(device), masks.to(device)\n",
        "                with autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "                    outputs = model(images)\n",
        "                    loss = loss_fn(outputs, masks)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                preds = torch.argmax(outputs, dim=1).detach()\n",
        "                val_iou += jaccard_index(masks, preds, num_classes=5).item() * images.size(0)  # Оновлено до 5 класів\n",
        "                val_count += images.size(0)\n",
        "                del images, masks, outputs, preds\n",
        "                torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "        if val_count > 0:\n",
        "            val_loss /= val_count\n",
        "            val_iou /= val_count\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['train_iou'].append(train_iou)\n",
        "    history['val_iou'].append(val_iou)\n",
        "\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    logging.info(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "                 f\"Train IoU: {train_iou:.4f}, Val IoU: {val_iou:.4f}, LR: {current_lr:.6f}, \"\n",
        "                 f\"Data: {data_time:.2f}s, Forward: {forward_time:.2f}s, Time: {time.time() - start_time:.2f}s\")\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, \"\n",
        "          f\"Train IoU: {train_iou:.4f}, Val IoU: {val_iou:.4f}, LR: {current_lr:.6f}, \"\n",
        "          f\"Data: {data_time:.2f}s, Forward: {forward_time:.2f}s, Time: {time.time() - start_time:.2f}s\")\n",
        "\n",
        "    if val_iou > best_val_iou:\n",
        "        best_val_iou = val_iou\n",
        "        save_path = f\"best_{model_configs[model_name]['save_prefix']}.pth\"\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        logging.info(f\"New best {model_name} model saved at epoch {epoch+1} with Val IoU: {val_iou:.4f}\")\n",
        "        print(f\"New best {model_name} model saved at epoch {epoch+1} with Val IoU: {val_iou:.4f}\")\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        save_path = f\"last_{model_configs[model_name]['save_prefix']}.pth\"\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache() if torch.cuda.is_available() else None"
      ],
      "metadata": {
        "id": "GpOT7W-kkOKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, val_loader, mean_ir, std_ir, use_crf=True):\n",
        "    start_time = time.time()\n",
        "    model.eval()\n",
        "    model_path = f\"best_{model_configs[model_name]['save_prefix']}.pth\"\n",
        "    if os.path.exists(model_path):\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        logging.info(f\"Loaded {model_path}\")\n",
        "        print(f\"Loaded {model_path}\")\n",
        "    else:\n",
        "        logging.warning(\"No saved model\")\n",
        "        print(\"No saved model\")\n",
        "\n",
        "    y_pred, y_true, per_image_iou = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for images, masks in val_loader:\n",
        "            if images.numel() == 0 or images.size(0) <= 1:\n",
        "                continue\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "            with autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "                outputs = model(images)\n",
        "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "            images_np = images.cpu().numpy()\n",
        "\n",
        "            refined_preds = np.argmax(probs, axis=1)\n",
        "\n",
        "            refined_preds = torch.from_numpy(refined_preds).to(device)\n",
        "\n",
        "            y_pred.append(refined_preds.cpu().numpy())\n",
        "            y_true.append(masks.cpu().numpy())\n",
        "            for i in range(images.size(0)):\n",
        "                iou = jaccard_index(masks[i:i+1], refined_preds[i:i+1], num_classes=5)\n",
        "                per_image_iou.append(iou.item())\n",
        "\n",
        "            del images, masks, outputs, probs, images_np, refined_preds\n",
        "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "    y_pred = np.concatenate(y_pred, axis=0)\n",
        "    y_true = np.concatenate(y_true, axis=0)\n",
        "\n",
        "    val_iou = jaccard_index(torch.tensor(y_true), torch.tensor(y_pred), num_classes=5)\n",
        "    val_dice = dice_coefficient(torch.tensor(y_true), torch.tensor(y_pred), num_classes=5)\n",
        "    val_accuracy = pixel_accuracy(torch.tensor(y_true), torch.tensor(y_pred))\n",
        "\n",
        "    logging.info(f\"Validation: IoU: {val_iou:.4f}, Dice: {val_dice:.4f}, Accuracy: {val_accuracy:.4f}, \"\n",
        "                 f\"IoU (mean ± std): {np.mean(per_image_iou):.4f} ± {np.std(per_image_iou):.4f}, Time: {time.time() - start_time:.2f}s\")\n",
        "    print(f\"Validation: IoU: {val_iou:.4f}, Dice: {val_dice:.4f}, Accuracy: {val_accuracy:.4f}, \"\n",
        "          f\"IoU (mean ± std): {np.mean(per_image_iou):.4f} ± {np.std(per_image_iou):.4f}, Time: {time.time() - start_time:.2f}s\")\n",
        "\n",
        "    cm = confusion_matrix(y_true.flatten(), y_pred.flatten(), labels=list(range(5)))\n",
        "    logging.info(f\"Confusion Matrix:\\n{cm}\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    return y_pred, y_true, per_image_iou\n",
        "y_pred, y_true, per_image_iou = evaluate_model(model, val_loader, mean_ir, std_ir, use_crf=True)\n"
      ],
      "metadata": {
        "id": "RikZOCNhtPHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_idx = 1\n",
        "image_indices = [8, 1, 15]\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i, (images, masks) in enumerate(val_loader):\n",
        "    if i != batch_idx:\n",
        "        continue\n",
        "\n",
        "    images = images[image_indices].to(device)\n",
        "    with torch.no_grad():\n",
        "        with autocast('cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "            outputs = model(images)\n",
        "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "            refined_preds = np.argmax(probs, axis=1)\n",
        "            images_np = images.cpu().numpy()\n",
        "\n",
        "    images = images.cpu().numpy()\n",
        "    masks = masks[image_indices].cpu().numpy()\n",
        "    classes_with_bg = ['Background', 'Person', 'Car','Bicycle',  'OtherVehicle']\n",
        "    colors = ['#000000', '#FF0000', '#00FF00', '#0000FF', '#FFFF00']\n",
        "    cmap = plt.cm.colors.ListedColormap(colors)\n",
        "    bounds = range(6)\n",
        "    norm = plt.cm.colors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "    for j, idx in enumerate(image_indices):\n",
        "        plt.subplot(len(image_indices), 3, j*3 + 1)\n",
        "        img_display = denormalize_image(images[j], mean_ir, std_ir)[0]\n",
        "        plt.imshow(img_display, cmap='gray')\n",
        "        plt.title(f'Image {idx} in Batch {batch_idx}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(len(image_indices), 3, j*3 + 2)\n",
        "        mask_display = masks[j]\n",
        "        im = plt.imshow(mask_display, cmap=cmap, norm=norm, alpha=0.8)\n",
        "        plt.title('Ground Truth')\n",
        "        plt.axis('off')\n",
        "        cbar = plt.colorbar(im, ticks=range(5), shrink=0.5)\n",
        "        cbar.ax.set_yticklabels(classes_with_bg)\n",
        "\n",
        "        plt.subplot(len(image_indices), 3, j*3 + 3)\n",
        "        pred_display = refined_preds[j]\n",
        "        im = plt.imshow(pred_display, cmap=cmap, norm=norm, alpha=0.8)\n",
        "        plt.title('Prediction')\n",
        "        plt.axis('off')\n",
        "        cbar = plt.colorbar(im, ticks=range(5), shrink=0.5)\n",
        "        cbar.ax.set_yticklabels(classes_with_bg)\n",
        "\n",
        "    break\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ac3gIj0drQc-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}